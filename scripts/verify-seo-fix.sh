#!/bin/bash

# å¤šè¯­è¨€SEOä¿®å¤éªŒè¯è„šæœ¬
# ç”¨äºéªŒè¯é‡å¤å†…å®¹é—®é¢˜ä¿®å¤æ˜¯å¦æˆåŠŸ

# ä¸åœ¨ CI ç¯å¢ƒä¸­é‡åˆ°é”™è¯¯ç«‹å³é€€å‡ºï¼ˆå…è®¸éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼‰
if [ -z "$CI" ]; then
    set -e
fi

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# é…ç½®
BASE_URL="${VERCEL_URL:-https://www.periodhub.health}"
TIMEOUT=10
LOG_FILE="seo-verification.log"

# è®¡æ•°å™¨
PASSED=0
FAILED=0

# åˆ›å»ºæ—¥å¿—æ–‡ä»¶
> "$LOG_FILE"

# è¾“å‡ºå‡½æ•°ï¼ŒåŒæ—¶å†™å…¥æ—¥å¿—
log_output() {
    if [ "$1" = "-e" ]; then
        # å¸¦é¢œè‰²è¾“å‡ºï¼ŒåŒæ—¶å†™å…¥æ—¥å¿—ï¼ˆå»é™¤é¢œè‰²ç ï¼‰
        shift
        echo -e "$@" | tee -a "$LOG_FILE"
        # åŒæ—¶å†™å…¥çº¯æ–‡æœ¬åˆ°æ—¥å¿—ï¼ˆå»é™¤ ANSI é¢œè‰²ç ï¼‰
        echo -e "$@" | sed 's/\x1b\[[0-9;]*m//g' >> "$LOG_FILE"
    else
        echo "$@" | tee -a "$LOG_FILE"
    fi
}

log_output "========================================="
log_output "  å¤šè¯­è¨€SEOä¿®å¤éªŒè¯"
log_output "========================================="
log_output ""
log_output "ç›®æ ‡URL: $BASE_URL"
log_output "æ—¶é—´: $(date)"
log_output "CIç¯å¢ƒ: ${CI:-å¦}"
log_output ""

# è¾…åŠ©å‡½æ•°ï¼šæ‰“å°æˆåŠŸ
print_success() {
    log_output -e "${GREEN}âœ… $1${NC}"
    ((PASSED++))
}

# è¾…åŠ©å‡½æ•°ï¼šæ‰“å°å¤±è´¥
print_failure() {
    log_output -e "${RED}âŒ $1${NC}"
    ((FAILED++))
    # åœ¨ CI ç¯å¢ƒä¸­ï¼ŒæŸäº›å¤±è´¥ä¸åº”è¯¥å¯¼è‡´è„šæœ¬é€€å‡º
    if [ -n "$CI" ]; then
        return 0
    fi
}

# è¾…åŠ©å‡½æ•°ï¼šæ‰“å°è­¦å‘Š
print_warning() {
    log_output -e "${YELLOW}âš ï¸  $1${NC}"
}

# æµ‹è¯•1: éªŒè¯æ ¹è·¯å¾„é‡å®šå‘
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
log_output "æµ‹è¯• 1: éªŒè¯æ ¹è·¯å¾„é‡å®šå‘"
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

REDIRECT_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}|%{redirect_url}" --max-time $TIMEOUT "$BASE_URL/" 2>&1 || echo "000|ERROR")
HTTP_CODE=$(echo "$REDIRECT_RESPONSE" | cut -d'|' -f1)
REDIRECT_URL=$(echo "$REDIRECT_RESPONSE" | cut -d'|' -f2)

log_output "HTTPçŠ¶æ€ç : $HTTP_CODE"
log_output "é‡å®šå‘URL: $REDIRECT_URL"

if [ "$HTTP_CODE" = "308" ] || [ "$HTTP_CODE" = "301" ]; then
    if [[ "$REDIRECT_URL" == *"/en"* ]] || [[ "$REDIRECT_URL" == *"/en" ]]; then
        print_success "æ ¹è·¯å¾„æ­£ç¡®é‡å®šå‘åˆ°è‹±æ–‡ç‰ˆæœ¬"
    else
        print_failure "æ ¹è·¯å¾„é‡å®šå‘ç›®æ ‡é”™è¯¯ (æœŸæœ›: /en, å®é™…: $REDIRECT_URL)"
    fi
else
    print_failure "æ ¹è·¯å¾„HTTPçŠ¶æ€ç é”™è¯¯ (æœŸæœ›: 308/301, å®é™…: $HTTP_CODE)"
fi
log_output ""

# æµ‹è¯•2: éªŒè¯æ ¹è·¯å¾„ noindex
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
log_output "æµ‹è¯• 2: éªŒè¯æ ¹è·¯å¾„ noindex"
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# æ³¨æ„ï¼šç”±äºæ ¹è·¯å¾„ä¼šé‡å®šå‘ï¼Œæˆ‘ä»¬éœ€è¦è·Ÿéšé‡å®šå‘æ¥æ£€æŸ¥æœ€ç»ˆé¡µé¢
# ä½†å®é™…ä¸Šæ ¹è·¯å¾„çš„ metadata åº”è¯¥åœ¨é‡å®šå‘ä¹‹å‰å°±è®¾ç½®äº†
ROOT_CONTENT=$(curl -s --max-time $TIMEOUT "$BASE_URL/" 2>&1 || echo "ERROR")

if echo "$ROOT_CONTENT" | grep -q 'content="noindex'; then
    print_success "æ ¹è·¯å¾„å·²è®¾ç½® noindex"
elif echo "$ROOT_CONTENT" | grep -q 'name="robots".*noindex'; then
    print_success "æ ¹è·¯å¾„å·²è®¾ç½® noindex (å¤‡ç”¨æ ¼å¼)"
else
    # ç”±äºé‡å®šå‘ï¼Œå¯èƒ½æ— æ³•ç›´æ¥æ£€æµ‹åˆ°ï¼Œç»™å‡ºè­¦å‘Šè€Œä¸æ˜¯å¤±è´¥
    print_warning "æ— æ³•æ£€æµ‹æ ¹è·¯å¾„ noindex (å¯èƒ½å› ä¸ºé‡å®šå‘)"
    log_output "æç¤º: è¯·æ‰‹åŠ¨éªŒè¯ app/page.tsx ä¸­çš„ robots.index = false"
fi
log_output ""

# æµ‹è¯•3: éªŒè¯è‹±æ–‡é¡µé¢ SEO é…ç½®
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
log_output "æµ‹è¯• 3: éªŒè¯è‹±æ–‡é¡µé¢ SEO é…ç½®"
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

EN_CONTENT=$(curl -s --max-time $TIMEOUT "$BASE_URL/en" 2>&1 || echo "ERROR")

# æ£€æŸ¥ canonical
if echo "$EN_CONTENT" | grep -q 'rel="canonical".*href=".*\/en"'; then
    print_success "è‹±æ–‡é¡µé¢ canonical æ­£ç¡®"
else
    print_failure "è‹±æ–‡é¡µé¢ canonical ç¼ºå¤±æˆ–é”™è¯¯"
fi

# æ£€æŸ¥ x-default
if echo "$EN_CONTENT" | grep -q 'hreflang="x-default".*href=".*\/en"'; then
    print_success "è‹±æ–‡é¡µé¢ x-default æ­£ç¡®"
else
    print_failure "è‹±æ–‡é¡µé¢ x-default ç¼ºå¤±æˆ–é”™è¯¯"
fi

# æ£€æŸ¥ robots
if echo "$EN_CONTENT" | grep -q 'content="index'; then
    print_success "è‹±æ–‡é¡µé¢å…è®¸ç´¢å¼•"
else
    print_failure "è‹±æ–‡é¡µé¢ robots é…ç½®é”™è¯¯"
fi
log_output ""

# æµ‹è¯•4: éªŒè¯ä¸­æ–‡é¡µé¢ SEO é…ç½®
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
log_output "æµ‹è¯• 4: éªŒè¯ä¸­æ–‡é¡µé¢ SEO é…ç½®"
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

ZH_CONTENT=$(curl -s --max-time $TIMEOUT "$BASE_URL/zh" 2>&1 || echo "ERROR")

# æ£€æŸ¥ canonical
if echo "$ZH_CONTENT" | grep -q 'rel="canonical".*href=".*\/zh"'; then
    print_success "ä¸­æ–‡é¡µé¢ canonical æ­£ç¡®"
else
    print_failure "ä¸­æ–‡é¡µé¢ canonical ç¼ºå¤±æˆ–é”™è¯¯"
fi

# æ£€æŸ¥ x-default æŒ‡å‘è‹±æ–‡
if echo "$ZH_CONTENT" | grep -q 'hreflang="x-default".*href=".*\/en"'; then
    print_success "ä¸­æ–‡é¡µé¢ x-default æ­£ç¡®æŒ‡å‘è‹±æ–‡"
else
    print_failure "ä¸­æ–‡é¡µé¢ x-default ç¼ºå¤±æˆ–é”™è¯¯"
fi

# æ£€æŸ¥ robots
if echo "$ZH_CONTENT" | grep -q 'content="index'; then
    print_success "ä¸­æ–‡é¡µé¢å…è®¸ç´¢å¼•"
else
    print_failure "ä¸­æ–‡é¡µé¢ robots é…ç½®é”™è¯¯"
fi
log_output ""

# æµ‹è¯•5: éªŒè¯ sitemap
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
log_output "æµ‹è¯• 5: éªŒè¯ Sitemap"
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

SITEMAP_CONTENT=$(curl -s --max-time $TIMEOUT "$BASE_URL/sitemap.xml" 2>&1 || echo "ERROR")

# æ£€æŸ¥æ˜¯å¦åŒ…å«æ ¹è·¯å¾„
if echo "$SITEMAP_CONTENT" | grep -q "<loc>$BASE_URL/<\/loc>"; then
    print_failure "Sitemap åŒ…å«æ ¹è·¯å¾„ (ä¸åº”è¯¥åŒ…å«)"
else
    print_success "Sitemap ä¸åŒ…å«æ ¹è·¯å¾„"
fi

# æ£€æŸ¥æ˜¯å¦åŒ…å«è‹±æ–‡é¡µé¢
if echo "$SITEMAP_CONTENT" | grep -q "<loc>.*\/en<\/loc>"; then
    print_success "Sitemap åŒ…å«è‹±æ–‡é¡µé¢"
else
    print_failure "Sitemap ç¼ºå°‘è‹±æ–‡é¡µé¢"
fi

# æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡é¡µé¢
if echo "$SITEMAP_CONTENT" | grep -q "<loc>.*\/zh<\/loc>"; then
    print_success "Sitemap åŒ…å«ä¸­æ–‡é¡µé¢"
else
    print_failure "Sitemap ç¼ºå°‘ä¸­æ–‡é¡µé¢"
fi
log_output ""

# æµ‹è¯•6: éªŒè¯ robots.txt
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
log_output "æµ‹è¯• 6: éªŒè¯ Robots.txt"
log_output "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

ROBOTS_CONTENT=$(curl -s --max-time $TIMEOUT "$BASE_URL/robots.txt" 2>&1 || echo "ERROR")

# æ£€æŸ¥æ˜¯å¦å…è®¸è‹±æ–‡å’Œä¸­æ–‡è·¯å¾„
if echo "$ROBOTS_CONTENT" | grep -q "Allow.*\/en"; then
    print_success "Robots.txt å…è®¸è‹±æ–‡è·¯å¾„"
else
    print_warning "Robots.txt æœªæ˜ç¡®å…è®¸è‹±æ–‡è·¯å¾„"
fi

if echo "$ROBOTS_CONTENT" | grep -q "Allow.*\/zh"; then
    print_success "Robots.txt å…è®¸ä¸­æ–‡è·¯å¾„"
else
    print_warning "Robots.txt æœªæ˜ç¡®å…è®¸ä¸­æ–‡è·¯å¾„"
fi

# æ£€æŸ¥æ˜¯å¦ç¦æ­¢ PDF
if echo "$ROBOTS_CONTENT" | grep -q "Disallow.*pdf"; then
    print_success "Robots.txt ç¦æ­¢ PDF æ–‡ä»¶"
else
    print_warning "Robots.txt æœªç¦æ­¢ PDF æ–‡ä»¶"
fi
log_output ""

# æ€»ç»“
log_output "========================================="
log_output "  éªŒè¯æ€»ç»“"
log_output "========================================="
log_output ""
log_output -e "${GREEN}é€šè¿‡: $PASSED${NC}"
log_output -e "${RED}å¤±è´¥: $FAILED${NC}"
log_output ""

# åœ¨ CI ç¯å¢ƒä¸­ï¼Œå…è®¸éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼ˆè­¦å‘Šçº§åˆ«ï¼‰
if [ $FAILED -eq 0 ]; then
    log_output -e "${GREEN}ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤šè¯­è¨€SEOé…ç½®æ­£ç¡®ã€‚${NC}"
    exit 0
elif [ -n "$CI" ] && [ $FAILED -le 2 ]; then
    # CI ç¯å¢ƒä¸­ï¼Œå¦‚æœå¤±è´¥æ•° <= 2ï¼Œè§†ä¸ºè­¦å‘Šè€Œéé”™è¯¯
    log_output -e "${YELLOW}âš ï¸  æœ‰ $FAILED ä¸ªæµ‹è¯•å¤±è´¥ï¼Œä½†å±äºå¯æ¥å—èŒƒå›´ã€‚${NC}"
    exit 0
else
    log_output -e "${RED}âš ï¸  æœ‰ $FAILED ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚${NC}"
    exit 1
fi
